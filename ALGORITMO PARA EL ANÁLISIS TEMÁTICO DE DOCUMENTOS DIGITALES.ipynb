{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Algoritmo de modelación de tópicos de documentos digitales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autores\n",
    "\n",
    "#### Luis Roberto Polo Bautista\n",
    "#### Karen Vanessa Martínez Acevedo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El objetivo del algoritmo es asignar áreas temáticasa de documentos digitales en PDF, que sirva como herramienta de apoyo al análisis temático dentro de la organización de la información,  con el fin de ser implementado en el desarrollo de vocabularios controlados, como: taxonomías, tesauros, ontologías, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversióndel texto completo de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En esta parte se utilizó el módulo PyMuPDF de Python, que entre otras funciones permite la identificación y conversión del texto de diferentes tipos de documentos a archivos editables. Es importante señalar que, el funcionamiento de este algoritmo toma como base documentos en  formato  PDF,  con  el  módulo PyMuPDF se  hace  uso  del  Reconocimiento  Óptico  de Caracteres,  que  permita  generar  archivos de texto  simple  (archivos  con  extensión  txt)  que contengan el texto completo de los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar los módulos necesario\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de páginas del documento:  311\n",
      "Datos bibligráficos:  {'format': 'PDF 1.4', 'title': None, 'author': None, 'subject': None, 'keywords': None, 'creator': 'Adobe InDesign 15.0 (Windows)', 'producer': 'Acrobat Distiller 10.1.16 (Windows)', 'creationDate': \"D:20200805195910+05'30'\", 'modDate': \"D:20200806191404+05'30'\", 'encryption': None}\n"
     ]
    }
   ],
   "source": [
    "# Importar el documentoen formato PDF\n",
    "documento_pdf=\"c:/\"#<<<<<<<<-----Escribe la ruta donde se encuentra el documento PDF----->>>>>>>>\n",
    "# Leer el documento mediante el módulo PyMuPDF\n",
    "documento=fitz.open(documento_pdf)\n",
    "# Mostrar el número de páginas y los datos bibliográficos\n",
    "print (\"Número de páginas del documento: \",documento.pageCount)\n",
    "print (\"Datos bibligráficos: \",documento.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarar un variable que contenga el nombre del nuevo archivo en formato txt\n",
    "documento_txt=open(documento_pdf + \".txt\", \"wb\")\n",
    " \n",
    "for paginas in documento: # Para todas las páginas del documento  hacer: \n",
    "    texto=paginas.getText().encode(\"utf8\") # Conversión del texto en formato UTF-8\n",
    "    documento_txt.write(texto) # Escribir el texto en un archivo con la extensión definida\n",
    "    documento_txt.write(b\"\\n-----\\n\")# Definir dentro del archivo las divisiones de cada página\n",
    "documento_txt.close() #Cerrar el documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de temas relevantes y modelación visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En  la  sección  de  identificación  de  temas se  utilizaron  los  módulos Numpy  y Scikit-Learn para el cálculo de frecuencia y vectores de palabrasy el modelo de Asignación Latente de Dirichlet (ALD) para la identificación de los temas relevantes. Para la visualización dinámica de los temaspor medio de HTML se utilizóel módulo pyLDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los módulos necesarios\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import os\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Importar el archivo de texto simple con el preprocesamiento realizado \n",
    "with open ('c:/Users/Luis/Desktop/book2.pdf.txt', 'r', encoding=\"utf-8\") as archivo: #<<<<<<<<-----Escribe la ruta donde se encuentra el documento txt----->>>>>>>>\n",
    "    texto= archivo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Eliminar los artículos, pronombres, preposiciones, etc., del texto \n",
    "agregar = ['No', 'text', 'returned', 'unable', 'to', 'reach', 'website.', 'one', 'new', '--', 'us'] #<<<<<<<<-----Escribe las palabras que no quiere que sean consideradas a parte de las palabras vacías----->>>>>>>>\n",
    "stop_words= (stopwords.words('spanish')) # <<<<<<<<-----para un texto en inglés, reemplazar 'spanish' por 'english' ----->>>>>>>>\n",
    "stop_words.extend (agregar)\n",
    "word_tokens= word_tokenize(texto.lower())\n",
    "word_tokens= list(filter(lambda token: token not in string.punctuation, word_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "filtro=[]\n",
    "for palabra in word_tokens: \n",
    "    if palabra not in stop_words:\n",
    "        filtro.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# normalizar todas las formas de una misma palabra \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_output = [lemmatizer.lemmatize(w) for w in filtro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Calcular los vectores de las palabras individuales que conforman cada frase \n",
    "vectores_palabras = CountVectorizer()\n",
    "transformar_vectores = vectores_palabras.fit_transform(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Crear una función que extraiga los vectores de las palabras y los guarde en una variable\n",
    "def mostrar_tópicos(model, vectores_palabras, n_top_words):\n",
    "    palabras = vectores_palabras.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([palabras[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:- 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Declarar en una variable el número de temas a procesas\n",
    "número_tópicos = 4\n",
    "# Declarar en una variable el número de palabras relacionadas a los temas\n",
    "número_palabras = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=4, n_jobs=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procesar los datos ingresados con base a modulo ALD\n",
    "lda = LDA(n_components=número_tópicos, n_jobs=-1)\n",
    "lda.fit(transformar_vectores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópicos encontrados mediante LDA:\n",
      "\n",
      "Topic #0:\n",
      "http learning work programme resource 2018 development year building stress strategy journal 2017 different 2019 beltman educational 2013 2012 day use skill response developing health beginning chap identity resilient framework\n",
      "\n",
      "Topic #1:\n",
      "education 10 org doi brite relationship support early educator also personal time chapter program career challenge individual participant impact emotional focus level demand important classroom life outcome australian 1080 principal\n",
      "\n",
      "Topic #2:\n",
      "resilience et teaching practice wellbeing positive self mansﬁeld study job training social process need may australia theory approach within colleague profession ed opportunity child review activity example two understanding efﬁcacy\n",
      "\n",
      "Topic #3:\n",
      "teacher al school module professional student research context well experience mindfulness pst 2016 service university pre factor way being emotion based 2014 psychology role quality 2011 common 2015 develop management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los datos procesados con base al vector asignado a cada palabra, así como el número de palabras relacionados a los tópicos \n",
    "print(\"Tópicos encontrados mediante LDA:\")\n",
    "mostrar_tópicos(lda, vectores_palabras, número_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Declarar en una variable el nombre del archivo que mostrara los temas de forma dinámica \n",
    "LDAvis_data_filepath = os.path.join('./tópic_'+str(número_tópicos))#<---- Escribe el nombre del archivo\n",
    "# Procesar los datos para que se puedan mostrar de forma dinámica\n",
    "if 1 == 1:LDAvis_prepared = sklearn_lda.prepare(lda, transformar_vectores, vectores_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Preparar el archivo con los datos a mostrar\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "with open(LDAvis_data_filepath, 'rb',) as f:\n",
    "    LDAvis_prepared = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Guardar el archivo en una ruta determinada con extensión HTML\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, 'c:/Users/Luis/Desktop/'+ str(LDAvis_data_filepath) +'.html')#<<<<<<<<-----Escribe la ruta donde se quiere guardar el archivo HTML---->>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
